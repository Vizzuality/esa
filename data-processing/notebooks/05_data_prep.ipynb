{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Library import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the log level to INFO\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_mbtiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mbtiles(\n",
    "    source_path: Path,\n",
    "    output_path: Path,\n",
    "    layer_name: str,\n",
    "    max_zoom: int,\n",
    "    opts=\"--read-parallel --no-tile-compression -s EPSG:4326 -B4\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Use tippecanoe to create pbf tiles at dest_path from source_path (geojson).\n",
    "    layer_name is used for the name of the layer in the MBTILE.\n",
    "    Regex file path (/*.geojson) is supported for source_path.\n",
    "    This function replaces the previous two functions (create_mbtiles & mbtile_to_pbf).\n",
    "\n",
    "    More info: https://github.com/mapbox/tippecanoe#options\n",
    "\n",
    "    Args:\n",
    "        source_path (Path): path to source geojson\n",
    "        output_path (Path): path to output .mbtiles\n",
    "        layer_name (str): name of layer in the MBTILE\n",
    "        max_zoom (int): max zoom level\n",
    "        opts (str): options for tippecanoe\n",
    "\n",
    "    Returns:\n",
    "        (int): 0 if the file was created successfully, 1 if the file creation failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        opts += f\" -z{max_zoom}\"\n",
    "        cmd = f\"tippecanoe -o {output_path} -l {layer_name} {opts} {source_path}\"\n",
    "        logger.info(f\"Processing: {cmd}\")\n",
    "        r = subprocess.call(cmd, shell=True)\n",
    "        if r == 0:\n",
    "            logger.info(\"Task created\")\n",
    "        return r\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random_point_in_polygon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_in_polygon(polygon):\n",
    "    \"\"\"\n",
    "    Generate a random point within a given polygon.\n",
    "    Args:\n",
    "        polygon (shapely.geometry.Polygon): The polygon within which to generate a random point.\n",
    "    Returns:\n",
    "        shapely.geometry.Point: A random point within the polygon.\n",
    "    \"\"\"\n",
    "    min_x, min_y, max_x, max_y = polygon.bounds\n",
    "    while True:\n",
    "        random_point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n",
    "        if polygon.contains(random_point):\n",
    "            return random_point"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***\n",
    "## Dhaka\n",
    "### Settlement extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_01 = (\n",
    "    \"GDA_Urban_Phase1_DLR_BGD_Dhaka_Settlement_Extent_and_Change_1985-2015_30m_1_0.tif\"\n",
    ")\n",
    "file_02 = \"GDA_Urban_Phase1_DLR_BGD_Dhaka_SettlementExtentandChange_HFC_2016-2022_quarterly_10m_1_0\\\n",
    ".tif\"\n",
    "\n",
    "datasets = {\n",
    "    \"01_Settlement_Extent_and_Change_1985-2015\": file_01,\n",
    "    \"02_Settlement_Extent_and_Change_2016-2022\": file_02,\n",
    "}\n",
    "\n",
    "years = {\n",
    "    \"01_Settlement_Extent_and_Change_1985-2015\": np.arange(1985, 2016, 1),\n",
    "    \"02_Settlement_Extent_and_Change_2016-2022\": np.arange(2016, 2023, 1),\n",
    "}\n",
    "\n",
    "year_relations = {\n",
    "    \"2022\": 1,\n",
    "    \"2021\": 5,\n",
    "    \"2020\": 9,\n",
    "    \"2019\": 13,\n",
    "    \"2018\": 17,\n",
    "    \"2017\": 21,\n",
    "    \"2016\": 25,\n",
    "}\n",
    "\n",
    "input_path = \"../data/raw/04_Products/BGD/Phase_1\"\n",
    "output_path = \"../data/raw/Dhaka/GeoTIFFs/Settlement\"\n",
    "\n",
    "mask_color = [251, 171, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, input_file in datasets.items():\n",
    "    # Read tiff\n",
    "    da = (\n",
    "        rxr.open_rasterio(os.path.join(input_path, dataset, input_file))\n",
    "        .squeeze()\n",
    "        .drop(\"band\")\n",
    "    )\n",
    "\n",
    "    # Create output directory\n",
    "    if not os.path.exists(os.path.join(output_path)):\n",
    "        os.makedirs(os.path.join(output_path))\n",
    "\n",
    "    # Loop through years\n",
    "    for year in years[dataset]:\n",
    "        # Create year mask\n",
    "        if dataset == \"02_Settlement_Extent_and_Change_2016-2022\":\n",
    "            t = year_relations[str(year)]\n",
    "            mask = da.where(da >= t, 0)\n",
    "            mask = mask.where(mask == 0, 1)\n",
    "        else:\n",
    "            mask = da.where(da <= year, 0)\n",
    "            mask = mask.where(mask == 0, 1)\n",
    "\n",
    "        # Reproject to 3857\n",
    "        mask_3857 = mask.rio.reproject(\"epsg:3857\")\n",
    "\n",
    "        # Create an RGBA array with the same shape as your mask\n",
    "        rgba = np.zeros((*mask_3857.shape, 4), dtype=np.uint8)\n",
    "\n",
    "        # Set the RGBa values where the mask is 1\n",
    "        rgba[mask_3857.values == 1, :3] = mask_color\n",
    "\n",
    "        # Set the alpha channel to 255 where the mask is 1 and 0 where the mask is 0\n",
    "        rgba[..., 3] = mask_3857.values * 255\n",
    "\n",
    "        # Get the transform and crs from the original mask\n",
    "        transform = mask_3857.rio.transform()\n",
    "        crs = mask_3857.rio.crs\n",
    "\n",
    "        # Open a new GeoTIFF file in write mode\n",
    "        with rio.open(\n",
    "            os.path.join(output_path, f\"Settlement_{year}.tif\"),\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=rgba.shape[0],\n",
    "            width=rgba.shape[1],\n",
    "            count=4,\n",
    "            dtype=rgba.dtype,\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "        ) as dst:\n",
    "            # Write the RGBa array to the file\n",
    "            dst.write(rgba.transpose((2, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/Dhaka/population_density_2021.geojson\"\n",
    "output_path = \"../data/processed/Dhaka/population_density_2021.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"population_density_2021\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## South Sudan\n",
    "### [HydroRIVERS v1.0](https://www.hydrosheds.org/products/hydrorivers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/South Sudan/HydroRIVERS_v10_af_SSD.geojson\"\n",
    "output_path = \"../data/processed/South Sudan/HydroRIVERS_v10_af_SSD.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"HydroRIVERS_v10_af_SSD\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg -Z4 --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = gpd.read_file(\n",
    "    \"../data/raw/Climate Resilience/South Sudan/WB_countries_Admin0_10m/WB_countries_Admin0_10m.shp\"\n",
    ")\n",
    "countries = countries[[\"ISO_A3\", \"NAME_EN\", \"geometry\"]]\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/raw/Climate Resilience/South Sudan/ESA GDA Programme Dashboard (GDA Website)_GDA AID \\\n",
    "    activities - in process and completed_Geo chart - Sheet1.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df,\n",
    "    countries,\n",
    "    left_on=\"Country\",\n",
    "    right_on=\"NAME_EN\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df)\n",
    "\n",
    "for _idx, row in gdf.iterrows():\n",
    "    count = int(row[\"EOIDs\"])\n",
    "    for _ in range(count):\n",
    "        rand_point = random_point_in_polygon(row[\"geometry\"])\n",
    "        new_rows.append(\n",
    "            {\"Country\": row[\"Country\"], \"ISO_A3\": row[\"ISO_A3\"], \"geometry\": rand_point}\n",
    "        )\n",
    "\n",
    "# Create the new GeoDataFrame using the same CRS as the original gdf\n",
    "new_gdf = gpd.GeoDataFrame(new_rows, crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.to_file(\"../data/processed/EOIDs_random_points.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Ukraine\n",
    "### Looting Locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"../data/raw/Fragility Conflict Security/\\\n",
    "    UC4_LandAndConflict/D3.4/D3.43/Locations Looting Ukraine.xlsx\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GeoDataFrame from the excel file containing the looting locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your Latitude and Longitude columns are not null\n",
    "df = df.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
    "\n",
    "# Create a new geometry column in your DataFrame\n",
    "df[\"geometry\"] = df.apply(lambda row: Point(row[\"Longitude\"], row[\"Latitude\"]), axis=1)\n",
    "\n",
    "# Convert your DataFrame to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as `GeoJSON`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"../data/processed/Ukraine/looting_locations.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looting Locations in Ukraine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ukraine = (\n",
    "    df.drop(columns=[\"Latitude\", \"Longitude\", \"Source\", \"geometry\"])\n",
    "    .groupby(\"Date\")\n",
    "    .count()\n",
    ")\n",
    "df_ukraine = df_ukraine.reset_index().rename(\n",
    "    columns={\"Date\": \"date\", \"Location\": \"count\"}\n",
    ")\n",
    "df_ukraine.plot(x=\"date\", y=\"count\", kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ukraine.to_csv(\n",
    "    \"../data/processed/Ukraine/looting_land_grabbing_mentions_ukraine.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looting Locations in Kherson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kherson = df[df[\"Location\"] == \"Kherson\"]\n",
    "df_kherson = (\n",
    "    df_kherson.drop(columns=[\"Latitude\", \"Longitude\", \"Source\", \"geometry\"])\n",
    "    .groupby(\"Date\")\n",
    "    .count()\n",
    ")\n",
    "df_kherson = df_kherson.reset_index().rename(\n",
    "    columns={\"Date\": \"date\", \"Location\": \"count\"}\n",
    ")\n",
    "df_kherson.plot(x=\"date\", y=\"count\", kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kherson.to_csv(\n",
    "    \"../data/processed/Ukraine/looting_land_grabbing_mentions_kherson.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Crop Monitoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\n",
    "    \"../data/raw/Fragility Conflict Security/UC4_LandAndConflict/\\\n",
    "        D3.4/D3.49/Harvestdates_zaporizhzya/test_shp.shp\"\n",
    ")\n",
    "gdf[\"#_of_harvest\"] = gdf[[\"Harvest_1\", \"Harvest_2\", \"Harvest_3\", \"Harvest_4\"]].apply(\n",
    "    lambda x: x.notnull().sum(), axis=1\n",
    ")\n",
    "cols = gdf.columns.tolist()\n",
    "cols.remove(\"geometry\")  # Remove 'geometry' from its current position\n",
    "cols.append(\"geometry\")  # Append 'geometry' at the end\n",
    "gdf = gdf[cols]  # Reorder the DataFrame\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as `GeoJSON`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs(epsg=4326)\n",
    "gdf.to_file(\n",
    "    \"../data/processed/Ukraine/seasonal_crop_monitoring.geojson\", driver=\"GeoJSON\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create `MBTiles`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/Ukraine/seasonal_crop_monitoring.geojson\"\n",
    "output_path = \"../data/processed/Ukraine/seasonal_crop_monitoring.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"Seasonal Crop Monitoring\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg -Z7 --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Nigeria\n",
    "### Ground Displacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\n",
    "    \"../data/processed/Nigeria/NGA_Warri_Ground_Displacement_SQ_2D_SNT_VERT_1_0.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = list(gdf.columns)[6:-1]\n",
    "\n",
    "# gdf['VCGD'] = gdf[date_columns].sum(axis=1)\n",
    "gdf = gdf.drop(date_columns, axis=1)\n",
    "## reordering columns\n",
    "# cols = list(gdf.columns)\n",
    "# cols.remove('geometry')\n",
    "# cols.append('geometry')\n",
    "# gdf = gdf[cols]\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as `GeoJSON`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\n",
    "    \"../data/processed/Nigeria/NGA_Warri_Ground_Displacement_SQ_2D_SNT_VERT_1_0.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Use / Land Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create `MBTiles`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/Nigeria/NGA_Warri_LULC_2022_1_0.geojson\"\n",
    "output_path = \"../data/processed/Nigeria/NGA_Warri_LULC_2022_1_0.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"Land Use Land Cover\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg -Z10 --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Pakistan\n",
    "### Transport Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\n",
    "    \"../data/raw/Urban Sustainability/04_Products/PAK/Phase_1/02_Transport_Network_2022/\\\n",
    "GDA_Urban_Phase1_GAF_PAK_Sargodha_Transport_Network_2022_1_0/\\\n",
    "GDA_Urban_Phase1_GAF_PAK_Sargodha_Transport_Network_2022_1_0.shp\"\n",
    ")\n",
    "gdf[\"Road_Type\"] = gdf[\"Road_Type\"].fillna(\"Transport\")\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"Road_Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as `GeoJSON`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\n",
    "    \"../data/processed/Pakistan/PAK_Sargodha_Transport_Network_2022_1_0.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Use / Land Cover\n",
    "**Create `MBTiles`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/Pakistan/PAK_Sargodha_LULC_2022_1_0.geojson\"\n",
    "output_path = \"../data/processed/Pakistan/PAK_Sargodha_LULC_2022_1_0.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"Land Use Land Cover\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg -Z10 --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Urban Heat Island Intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\n",
    "    \"../data/raw/Urban Sustainability/04_Products/PAK/Phase_1/\\\n",
    "04_Surface_Urban_Heat_Island_Intensity_2021/\\\n",
    "GDA_Urban_Phase1_GAF_PAK_Sargodha_LULCinclSUHII_2021_1_0/\\\n",
    "GDA_Urban_Phase1_GAF_PAK_Sargodha_LULCinclSUHII_2021_1_0.shp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for the temperature categories\n",
    "labels = [\n",
    "    \"coolest\",\n",
    "    \"moderately warmer\",\n",
    "    \"warmer\",\n",
    "    \"moderately hotter\",\n",
    "    \"hotter\",\n",
    "    \"hottest\",\n",
    "]\n",
    "\n",
    "# Use pandas qcut function to categorize 'SUHII_AVG' into different bins\n",
    "# The number of bins is equal to the number of labels\n",
    "# Each bin has approximately the same number of records\n",
    "# The result is stored in a new column 'SUHII_Category'\n",
    "gdf[\"SUHII_Category\"] = pd.qcut(gdf[\"SUHII_AVG\"], q=len(labels), labels=labels)\n",
    "\n",
    "# Convert the 'Temperature_Category' column to string type\n",
    "gdf[\"SUHII_Category\"] = gdf[\"SUHII_Category\"].astype(str)\n",
    "\n",
    "# reordering columns\n",
    "cols = list(gdf.columns)\n",
    "cols.remove(\"geometry\")\n",
    "cols.append(\"geometry\")\n",
    "gdf = gdf[cols]\n",
    "\n",
    "# Change the CRS to EPSG 4326\n",
    "gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save as `GeoJSON`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\n",
    "    \"../data/processed/Pakistan/PAK_Sargodha_LULCinclSUHII_2021_1_0.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create `MBTiles`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/processed/Pakistan/PAK_Sargodha_LULCinclSUHII_2021_1_0.geojson\"\n",
    "output_path = \"../data/processed/Pakistan/PAK_Sargodha_LULCinclSUHII_2021_1_0.mbtiles\"\n",
    "create_mbtiles(\n",
    "    file_path,\n",
    "    output_path,\n",
    "    \"Land Use Land Cover\",\n",
    "    16,\n",
    "    \"--force --read-parallel -zg -Z10 --drop-densest-as-needed --extend-zooms-if-still-dropping\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esa_gda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
